"""
Load Universal Transactions to DB (Standalone)

Script to load the CSV generated by universal_pdf_parser.py into the PostgreSQL database.
INLINE DB CONNECTION to avoid module import issues.
"""
import pandas as pd
import sys
import os
from sqlalchemy import create_engine, text
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

def get_db_url_inline():
    # Load .env manually
    env_path = Path(__file__).parent.parent / '.env'
    load_dotenv(env_path)
    
    user = os.getenv("POSTGRES_USER", "postgres")
    password = os.getenv("POSTGRES_PASSWORD", "postgres")
    server = os.getenv("POSTGRES_SERVER", "localhost")
    port = os.getenv("POSTGRES_PORT", "5432")
    db = os.getenv("POSTGRES_DB", "warroom")
    return f"postgresql://{user}:{password}@{server}:{port}/{db}"

CSV_PATH = "data/extracted/BG_SAXO_Transactions_FinalVersion.csv"
# Correct valid holdings file found in directory (contains ISINs)
HOLDINGS_PATH = "data/extracted/bgsaxo/Posizioni_19-dic-2025_17_49_12.csv.json"

def load_isin_map():
    """Load ISIN -> Ticker map from Holdings JSON (Case Insensitive)"""
    import json
    if not os.path.exists(HOLDINGS_PATH):
        print(f"‚ö†Ô∏è Holdings file not found: {HOLDINGS_PATH}")
        return {}
    
    with open(HOLDINGS_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)
        
    isin_map = {}
    
    # Handle both list and dict wrapper (support 'data' and 'holdings' keys)
    holdings_list = data if isinstance(data, list) else (data.get('data', []) or data.get('holdings', []))
    
    for h in holdings_list:
        isin = h.get('isin')
        # Support both 'instrument_symbol' and 'ticker' and 'symbol'
        symbol = h.get('instrument_symbol') or h.get('ticker') or h.get('symbol')
        
        if isin and symbol:
            # Case Insensitive Key: Store ISIN as UPPERCASE
            isin_map[isin.upper().strip()] = symbol
            
    print(f"üó∫Ô∏è Loaded {len(isin_map)} ISIN mappings (Case Insensitive).")
    return isin_map

def get_db_url_inline():
    # Load .env manually
    env_path = Path(__file__).parent.parent / '.env'
    load_dotenv(env_path)
    
    user = os.getenv("POSTGRES_USER", "postgres")
    password = os.getenv("POSTGRES_PASSWORD", "postgres")
    server = os.getenv("POSTGRES_SERVER", "localhost")
    port = os.getenv("POSTGRES_PORT", "5432")
    db = os.getenv("POSTGRES_DB", "warroom")
    return f"postgresql://{user}:{password}@{server}:{port}/{db}"

# Italian Month Map
IT_MONTHS = {
    'gen': 'Jan', 'feb': 'Feb', 'mar': 'Mar', 'apr': 'Apr', 'mag': 'May', 'giu': 'Jun', 
    'lug': 'Jul', 'ago': 'Aug', 'set': 'Sep', 'ott': 'Oct', 'nov': 'Nov', 'dic': 'Dec'
}

def parse_italian_date(date_str):
    if not isinstance(date_str, str):
        return pd.to_datetime(date_str)
    
    clean_date = date_str.lower().strip()
    for it, en in IT_MONTHS.items():
        if f"-{it}-" in clean_date or f" {it} " in clean_date:
            clean_date = clean_date.replace(it, en)
            break
            
    return pd.to_datetime(clean_date)

def parse_italian_float(val):
    """
    Parses a string like '1.200,50' or '301,93' into a float.
    Handles 'EUR/USD' suffixes if present.
    """
    if pd.isna(val) or val is None:
        return 0.0
    
    s = str(val).strip()
    
    # Remove currency symbols/text if accidentally captured
    s = s.replace("EUR", "").replace("USD", "").strip()
    
    # Handle negative sign
    sign = 1
    if s.startswith("-"):
        sign = -1
        s = s[1:]
        
    # Standard Italian format: 1.234,56 -> remove dots, replace comma with dot
    # But sometimes PDF extraction gives '1234,56' or '1,234.56'.
    # Heuristic: if ',' is the last separator, it's decimal.
    
    if "," in s and "." in s:
        if s.find(",") > s.find("."): # 1.234,56
             s = s.replace(".", "").replace(",", ".")
        else: # 1,234.56
             s = s.replace(",", "")
    elif "," in s:
        s = s.replace(",", ".")
        
    try:
        return float(s) * sign
    except ValueError:
        return 0.0

def load_data():
    print("\nüîç STARTING UNIVERSAL LOADER (STANDALONE)...")
    
    if not os.path.exists(CSV_PATH):
        print(f"‚ùå File not found: {CSV_PATH}")
        return

    print(f"üìÇ Loading: {CSV_PATH}")
    df = pd.read_csv(CSV_PATH)
    
    # Load Mapping (Keys are UPPERCASE)
    isin_map = load_isin_map()
    # Debug Mapping Size
    if not isin_map:
        print("‚ö†Ô∏è Warning: ISIN Map is empty. Check JSON structure.")
        try:
            import json
            with open(HOLDINGS_PATH, 'r', encoding='utf-8') as f:
                snippet = json.load(f)
                if isinstance(snippet, dict):
                    print(f"JSON Keys: {list(snippet.keys())}")
                    if 'data' in snippet:
                         print(f"First item in 'data': {snippet['data'][0] if snippet['data'] else 'Empty List'}")
        except Exception as e:
            print(f"JSON Debug Error: {e}")
    
    # Map Operations to DB Enums
    op_map = {
        'BUY': 'BUY',
        'Acquista': 'BUY',
        'AUTO_BUY': 'BUY', 
        'SELL': 'SELL',
        'Vendi': 'SELL',
        'AUTO_SELL': 'SELL', 
        'DEPOSIT': 'DEPOSIT',
        'Deposito': 'DEPOSIT',
        'WITHDRAW': 'WITHDRAW',
        'Prelievo': 'WITHDRAW',
        'DIVIDEND': 'DIVIDEND',
        'Div': 'DIVIDEND',
        'CORP_ACTION': 'DIVIDEND', 
        'FEE': 'FEE'
    }
    
    df['operation'] = df['type'].map(op_map).fillna('UNKNOWN')
    
    DB_URL = get_db_url_inline()
    engine = create_engine(DB_URL)
    
    with engine.begin() as conn:
        print("üßπ Cleaning old 'pdf_import' data...")
        # Aggressive Cleanup: Remove ALL 'bgsaxo' transactions marked as IMPORTED
        # preventing stale data.
        # Note: 'source' column does NOT exist in this DB schema version.
        conn.execute(text("DELETE FROM transactions WHERE broker = 'bgsaxo' AND status = 'IMPORTED'"))
        
        # Normalize Broker Name
        TARGET_BROKER = "bgsaxo"
        print(f"üöÄ Inserting {len(df)} rows for broker: {TARGET_BROKER}...")
        
        # Normalize Column Names (Handle LLM variations)
        col_rename_map = {
            'qty': 'quantity',
            'prezzo': 'price',
            'data': 'date',
            'tipo': 'type',
            'importo': 'total_amount',
            'importo_contabilizzato': 'total_amount',
            # Do NOT map 'ticker' to 'raw_name' if we want to keep 'ticker'
            # But ensure 'raw_name' exists if needed
            'descrizione': 'raw_name' 
        }
        df.rename(columns=col_rename_map, inplace=True)
        
        # Normalize Dataframe Columns (Robustness against LLM variances)
        expected_cols = ['isin', 'raw_name', 'ticker', 'currency', 'operation', 'status', 'page', 'fees', 'quantity', 'price', 'date', 'type', 'total_amount']
        for col in expected_cols:
            if col not in df.columns:
                df[col] = None

        for _, row in df.iterrows():
            # Limit Enforcement
            broker = TARGET_BROKER[:50]
            
            # Clean ISIN
            # Robust ISIN access (Extraction might not capture it)
            raw_isin = None
            if 'isin' in row and pd.notna(row['isin']):
                 raw_isin = row['isin']
            isin = raw_isin[:12] if raw_isin else None
            
            # Ticker Resolution Logic (Rosetta Stone - Case Insensitive)
            # Ticker Resolution Logic (Rosetta Stone - Case Insensitive)
            # 1. Try JSON 'ticker' field (Clean name from regex)
            json_ticker = row.get('ticker')
            if pd.notna(json_ticker) and str(json_ticker).strip():
                resolved_ticker = str(json_ticker).strip()
            # 2. Try to find Ticker via ISIN
            elif isin and isin.upper().strip() in isin_map:
                resolved_ticker = isin_map[isin.upper().strip()] # Use mapped 'NOW:xnys'
            elif isin:
                resolved_ticker = isin # Fallback to ISIN
            else:
                 # 3. Last Report: raw_name from column mapping or original
                resolved_ticker = str(row.get('raw_name') or row.get('description') or "UNKNOWN")
                
            # Force truncation to 20 chars max (DB limit)
            ticker = str(resolved_ticker)[:20] 
            
            # Operation & Status limits
            operation = row['operation'][:20]
            status = "IMPORTED"[:20]
            
            # Notes can be TEXT (unlimited usually, but safe to keep)
            notes_str = f"Original: {row['raw_name']} | Type: {row['type']}"
            
            # Derived fields using robust parser
            qty = parse_italian_float(row['quantity'])
            px = parse_italian_float(row['price'])
            total_amount = abs(parse_italian_float(row['total_amount'])) # Absolute for storage
            fees_val = parse_italian_float(row['fees']) if 'fees' in row else 0.0

            # Parse Page safely
            try:
                page_val = int(row['page']) if pd.notna(row['page']) else 1
            except:
                page_val = 1
            
            try:
                conn.execute(
                    text("""
                        INSERT INTO transactions 
                        (id, broker, ticker, isin, operation, quantity, price, total_amount, currency, fees, timestamp, source_document, source_page, notes, status)
                        VALUES (gen_random_uuid(), :broker, :ticker, :isin, :operation, :quantity, :price, :total_amount, :currency, :fees, :timestamp, :source_document, :source_page, :notes, :status)
                    """),
                    {
                        "broker": broker,
                        "ticker": ticker,
                        "isin": isin,
                        "operation": operation,
                        "quantity": qty,
                        "price": px,
                        "total_amount": total_amount,
                        "currency": str(row['currency'])[:3] if pd.notna(row['currency']) else 'EUR',
                        "fees": fees_val,
                        "timestamp": parse_italian_date(row['date']),
                        "source_document": "Transactions_19807401_2024-11-26_2025-12-19.pdf"[:255],
                        "source_page": page_val,
                        "notes": notes_str,
                        "status": status
                    }
                )
            except Exception as e:
                print(f"‚ùå Failed Row: {ticker} | {operation} | {e}")
                raise e # Stop on error to fix it
            
    print("‚úÖ Data successfully loaded into DB with Broker attribution and ISIN mapping!")

if __name__ == "__main__":
    load_data()
