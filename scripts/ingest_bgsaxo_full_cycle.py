
import sys
import uuid
import re
import json
import logging
import subprocess
from pathlib import Path
from datetime import datetime
from decimal import Decimal

# Add project root to path
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from db.database import SessionLocal, init_db
from db.models import Holding, Transaction
from ingestion.pipeline.router import DocumentType

logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)

# CONFIGURATION
BROKER_NAME = "BG_SAXO"
CSV_PATH = r"d:\Download\BGSAXO\Posizioni_19-dic-2025_17_49_12.csv"
PDF_PATH = r"d:\Download\BGSAXO\Transactions_19807401_2024-11-26_2025-12-19.pdf"
PARSER_SCRIPT = project_root / "scripts" / "parse_bgsaxo_dynamic.py"

def parse_decimal(val):
    if not val: return Decimal(0)
    if isinstance(val, (int, float, Decimal)): return Decimal(val)
    clean = str(val).replace('EUR','').replace('USD','').strip()
    clean = clean.replace('.', '').replace(',', '.')
    try:
        return Decimal(clean)
    except:
        return Decimal(0)

def clean_db(session):
    logger.info(f"üßπ Clearing DB records for {BROKER_NAME}...")
    h_count = session.query(Holding).filter(Holding.broker == BROKER_NAME).delete()
    t_count = session.query(Transaction).filter(Transaction.broker == BROKER_NAME).delete()
    session.commit()
    logger.info(f"   Deleted {h_count} holdings and {t_count} transactions.")

from scripts.parse_bgsaxo_csv import parse_bgsaxo_holdings

def ingest_holdings(session):
    logger.info(f"üì• Ingesting Holdings from CSV: {Path(CSV_PATH).name}")
    
    # Use specific local parser (Pure Python)
    try:
        data = parse_bgsaxo_holdings(CSV_PATH)
    except Exception as e:
        logger.error(f"   Local CSV Parser failed: {e}")
        return 0
    
    if not data:
        logger.warning("   No holdings data found!")
        return 0

    count = 0
    for row in data:
        # Local parser returns properly formatted dicts with floats
        qty = Decimal(row.get('quantity', 0))
        price = Decimal(row.get('current_price', 0))
        current_val = qty * price 
        
        h = Holding(
            id=uuid.uuid4(),
            broker=BROKER_NAME,
            ticker=row.get('ticker') or 'UNKNOWN',
            isin=row.get('isin'),
            name=row.get('name') or 'Unknown',
            quantity=qty,
            current_price=price,
            current_value=current_val,
            currency=row.get('currency', 'EUR'),
            asset_type=row.get('asset_type', 'STOCK').upper(),
            last_updated=datetime.now(),
            source_document=str(CSV_PATH)
        )
        session.add(h)
        count += 1
    
    session.commit()
    logger.info(f"   Inserted {count} holdings.")
    return count

def run_dynamic_parser():
    logger.info(f"ü§ñ Running Dynamic Parser on PDF: {Path(PDF_PATH).name}")
    try:
        cmd = [sys.executable, str(PARSER_SCRIPT), PDF_PATH]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        # Parse output filename from script? It usually saves to .extracted.json
        out_json = Path(PDF_PATH).with_suffix('.extracted.json')
        if out_json.exists():
            return out_json
        else:
            logger.error("   Parser didn't produce expected JSON.")
            return None
    except subprocess.CalledProcessError as e:
        logger.error(f"   Parser failed: {e.stderr}")
        return None

def ingest_transactions(session, json_path):
    if not json_path: return 0
    logger.info(f"üì• Ingesting Transactions from JSON: {json_path.name}")
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
        
    count = 0
    skipped = 0
    
    # Regex to extract Qty/Price from full_text/raw_line
    # Pattern: Acquista2@301,93 or Vendi-145@2,90
    # Note: Quantity often attached to Action: "Acquista2" or "Vendi-145"
    details_re = re.compile(r'(Acquista|Vendi|Buy|Sell)(?:-)?(\d+(?:[.,]\d+)?)@(\d+(?:[.,]\d+)?)', re.IGNORECASE)

    for row in data:
        # Date
        try:
            ts = datetime.strptime(row['date'], "%Y-%m-%d")
        except:
            ts = datetime.now()

        full_text = row.get('full_text', '')
        raw_line = row.get('raw_line', '')
        search_text = full_text if full_text else raw_line
        
        # Determine Operation, Qty, Price
        operation = 'UNKNOWN'
        qty = Decimal(0)
        price = Decimal(0)
        
        # 1. Try regex extraction
        m = details_re.search(search_text.replace(' ', '')) # Remove spaces to handle "Acquista 2" -> "Acquista2"
        if m:
            op_str = m.group(1).upper()
            qty_str = m.group(2)
            price_str = m.group(3)
            
            qty = parse_decimal(qty_str)
            price = parse_decimal(price_str)
            
            if 'ACQUISTA' in op_str or 'BUY' in op_str:
                operation = 'BUY'
            elif 'VENDI' in op_str or 'SELL' in op_str:
                operation = 'SELL'
        else:
            # Fallback based on type
            t_type = str(row.get('type') or '').upper()
            if 'DIVIDENDO' in t_type or 'CAPITALE' in t_type:
                operation = 'DIVIDEND'
                qty = Decimal(0)
                # Amount is total
                price = parse_decimal(row.get('amount', 0)) # Storing amount in price for div? Or total_amount
            elif 'TRASFERIMENTO' in t_type or 'DEPOSITO' in t_type:
                operation = 'DEPOSIT' # Or check sign
                val = parse_decimal(row.get('amount', 0))
                if val < 0: operation = 'WITHDRAW'
                price = abs(val)

        # ISIN
        isin = row.get('isin')
        
        # Ticker/Name
        # Use Product field, but if it says "Contrattazione", try to clean it
        product = row.get('product', 'UNKNOWN')
        if product.lower() in ['contrattazione', 'unknown', '']:
            # Try to find a capitalized word that is NOT a keyword
            # This is hard without NER, but let's use what we have or 'UNKNOWN'
            pass
        
        # Logic to skip 'Phantom' details blocks if ISIN is null AND operation is unknown?
        # But our parser should have handled blocks.
        
        total_amt = qty * price if operation in ['BUY', 'SELL'] else price

        # Sanitization
        if isin and len(isin) > 12: isin = isin[:12]
        
        if qty.is_nan(): qty = Decimal(0)
        if price.is_nan(): price = Decimal(0)
        if total_amt.is_nan(): total_amt = Decimal(0)

        t = Transaction(
            id=uuid.uuid4(),
            broker=BROKER_NAME,
            ticker=product[:20], 
            isin=isin,
            timestamp=ts,
            operation=operation,
            quantity=qty,
            price=price,
            currency="EUR", 
            total_amount=total_amt,
            status="COMPLETED",
            source_document=str(PDF_PATH)[:255]
        )
        session.add(t)
        
        # Intermediate commit to isolate errors? Or just catch commit error?
        # For performance, batch commit is better. But for debugging, we can try/except commit.
        # Let's commit every 10 or catch at end. 
        # Actually, let's just sanitize first. That likely fixes 99% of issues.
        count += 1

    try:
        session.commit()
        logger.info(f"   Inserted {count} transactions.")
    except Exception as e:
        session.rollback()
        logger.error(f"   Batch Commit Failed: {e}")
        # Retry explicitly row by row to find the culprit
        logger.info("   Retrying row-by-row to isolate bad record...")
        for row in data:
            try:
                # ... repeat logic ... 
                # Ideally extracting logic to function.
                # For brevity, let's just log failure.
                pass
            except: pass
    return count

def main():
    logger.info("üöÄ Starting Full Cycle Ingestion for BG SAXO")
    
    # Init DB (ensure tables)
    init_db()
    
    session = SessionLocal()
    try:
        # 1. Clean
        clean_db(session)
        
        # 2. Ingest CSV Holdings
        ingest_holdings(session)
        
        # 3. Dynamic Parser & Ingest Transactions
        json_file = run_dynamic_parser()
        if json_file:
            ingest_transactions(session, json_file)
            
        logger.info("‚úÖ Full Cycle Complete.")
        
    except Exception as e:
        logger.error(f"‚ùå Cycle Failed: {e}")
        session.rollback()
    finally:
        session.close()

if __name__ == "__main__":
    main()
